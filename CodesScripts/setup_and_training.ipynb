{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace,Dataset\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "dataset_name = 'hdfdata'\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')\n",
        "# Get a dataset by name\n",
        "hdf_ds = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
        "\n",
        "hdf_ds.to_path()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "zf-poc-hp\nzf-aml-hp\naustraliaeast\n2bd536a1-23a8-4193-be1e-219890bbd881\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "['/_2021_06_30_181821#CANape19_log_124.BLF.h5',\n '/_2021_06_30_181923#CANape16_log_008.BLF.h5',\n '/_2021_06_30_182321#CANape19_log_125.BLF.h5',\n '/_2021_06_30_182423#CANape16_log_009.BLF.h5',\n '/_2021_06_30_182821#CANape19_log_126.BLF.h5',\n '/_2021_06_30_182923#CANape16_log_010.BLF.h5',\n '/_2021_06_30_183423#CANape16_log_011.BLF.h5',\n '/_2021_06_30_183821#CANape19_log_128.BLF.h5',\n '/_2021_06_30_183923#CANape16_log_012.BLF.h5',\n '/_2021_06_30_184039#CANape19_log_136.BLF.h5']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1634702030378
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'train-with-hdf'\n",
        "\n",
        "from azureml.core import Experiment\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1634702035356
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "import os\n",
        "\n",
        "# choose a name for your cluster\n",
        "compute_name = os.environ.get('AML_COMPUTE_CLUSTER_NAME', 'cpu-cluster')\n",
        "compute_min_nodes = os.environ.get('AML_COMPUTE_CLUSTER_MIN_NODES', 0)\n",
        "compute_max_nodes = os.environ.get('AML_COMPUTE_CLUSTER_MAX_NODES', 4)\n",
        "\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
        "vm_size = os.environ.get('AML_COMPUTE_CLUSTER_SKU', 'Standard_DS11_v2')\n",
        "\n",
        "\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('found compute target. just use it. ' + compute_name)\n",
        "else:\n",
        "    print('creating a new compute target...')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                                min_nodes=compute_min_nodes, \n",
        "                                                                max_nodes=compute_max_nodes)\n",
        "\n",
        "    # create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    \n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \n",
        "    # if no min node count is provided it will use the scale settings for the cluster\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
        "    \n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found compute target. just use it. cpu-cluster\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1634702038990
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\n",
        "\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- scikit-learn\n",
        "- pip:\n",
        "  - azureml-defaults\n",
        "  - torch==1.9.1\n",
        "  - h5py==3.1.0\n",
        "  - progressbar>=2.5\n",
        "  - matplotlib\n",
        "  - torchvision"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting conda_dependencies.yml\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "pytorch_env = Environment.from_conda_specification(name = 'pytorch-env', file_path = './conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1634702049092
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "import tempfile\n",
        "#datastore = ws.get_default_datastore()\n",
        "#thisdataset = Dataset.File.from_files(path=(datastore, 'hdf_data'))\n",
        "#print(\"DATA PATH: \" + thisdataset.to_path()->list)\n",
        "##print(\"LIST FILES IN DATA PATH...\")\n",
        "#print(os.listdir(thisdataset.to_path()))\n",
        "hdf_ds = Dataset.get_by_name(workspace=ws, name=dataset_name)\n",
        "script_folder = os.getcwd()\n",
        "print(script_folder)\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script='Trainer.py',\n",
        "                      arguments=['--data_path',hdf_ds.as_mount()],\n",
        "                      compute_target=compute_target,\n",
        "                      environment=pytorch_env)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/ttttttt/code/Users/huping1006/ZF_new/scripts\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1634702052986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml._restclient.snapshots_client\n",
        "azureml._restclient.snapshots_client. SNAPSHOT_MAX_SIZE_BYTES =1000000000000"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1634702060204
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(src)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Submitting /mnt/batch/tasks/shared/LS_root/mounts/clusters/ttttttt/code/Users/huping1006/ZF_new/scripts directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1634702084979
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = run.register_model(model_name='pytorch-BD', model_path= 'outputs/thismodel.pt')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1634702590503
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}